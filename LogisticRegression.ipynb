{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966ddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e10c3",
   "metadata": {},
   "source": [
    "Import the libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f326b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix)\n",
    "from sklearn.feature_selection import RFE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0754f6c4",
   "metadata": {},
   "source": [
    "Step 1: Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5004ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('heart_failure_clinical_records.csv')\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "print(\"\\nClass Balance:\\n\", df['DEATH_EVENT'].value_counts(normalize=True))\n",
    "print(\"\\nSummary Statistics:\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca54f8c",
   "metadata": {},
   "source": [
    "Step 2: data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3537138",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['age', 'creatinine_phosphokinase', 'platelets', 'serum_creatinine', \n",
    "                'serum_sodium', 'ejection_fraction', 'time']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    lower = df[col].quantile(0.01)\n",
    "    upper = df[col].quantile(0.99)\n",
    "    df[col] = np.clip(df[col], lower, upper)\n",
    "    \n",
    "    if df[col].skew() > 1 and (df[col] > 0).all():\n",
    "        df[col] = np.log1p(df[col])\n",
    "        print(f\"Log-transformed {col} due to skewness: {df[col].skew():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50395b51",
   "metadata": {},
   "source": [
    "Step 3: Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d499cb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin age groups\n",
    "bins = [0, 50, 70, 120]\n",
    "df['age_group'] = pd.cut(df['age'], bins=bins, labels=['YOUNG', 'MID', 'OLD'], include_lowest=True)\n",
    "df = df.drop('age', axis=1)\n",
    "\n",
    "# Creatinine/ejection fraction ratio\n",
    "df['creatinine_ejection_ratio'] = df['serum_creatinine'] / df['ejection_fraction'].replace(0, np.finfo(float).eps)\n",
    "\n",
    "# Bin time groups\n",
    "time_bins = [0, df['time'].quantile(0.33), df['time'].quantile(0.66), df['time'].max()]\n",
    "time_labels = ['SHORT', 'MEDIUM', 'LONG']\n",
    "df['time_group'] = pd.cut(df['time'], bins=time_bins, labels=time_labels, include_lowest=True)\n",
    "df = df.drop('time', axis=1)\n",
    "\n",
    "# Comorbidity count\n",
    "df['comorbidity_count'] = df[['diabetes', 'high_blood_pressure', 'anaemia']].sum(axis=1)\n",
    "\n",
    "\n",
    "# Step 4: Categorical encoding\n",
    "df = pd.get_dummies(df, columns=['age_group', 'time_group'], prefix=['age_group', 'time_group'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee2c7d2",
   "metadata": {},
   "source": [
    "Step 4: Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea6271",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('DEATH_EVENT', axis=1)\n",
    "y = df['DEATH_EVENT']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"\\nTraining Set Size:\", X_train.shape[0], \"rows\")\n",
    "print(\"Test Set Size:\", X_test.shape[0], \"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bbf73",
   "metadata": {},
   "source": [
    "Step 5: Scale numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f29bbcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['creatinine_phosphokinase', 'platelets', 'serum_creatinine', \n",
    "                'serum_sodium', 'ejection_fraction', 'creatinine_ejection_ratio']\n",
    "scaler = StandardScaler()\n",
    "X_train_numeric = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test_numeric = scaler.transform(X_test[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f48ef",
   "metadata": {},
   "source": [
    "Step 6: Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f70043",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = ['sex', 'smoking', 'diabetes', 'anaemia', 'high_blood_pressure', 'comorbidity_count']\n",
    "categorical_cols = [col for col in df.columns if col.startswith('age_group') or col.startswith('time_group')]\n",
    "X_train = np.hstack([X_train_numeric, X_train[binary_cols].values, X_train[categorical_cols].values])\n",
    "X_test = np.hstack([X_test_numeric, X_test[binary_cols].values, X_test[categorical_cols].values])\n",
    "feature_names = numeric_cols + binary_cols + categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d2c89",
   "metadata": {},
   "source": [
    "Step 7: Handle class imbalance with SMOTE, feature selection with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3b7a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "print(\"\\nAfter SMOTE - Class Balance:\\n\", pd.Series(y_train_balanced).value_counts())\n",
    "\n",
    "# Step 9: Feature selection with RFE\n",
    "model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "rfe = RFE(estimator=model, n_features_to_select=8)\n",
    "X_train_balanced = rfe.fit_transform(X_train_balanced, y_train_balanced)\n",
    "X_test = rfe.transform(X_test)\n",
    "\n",
    "selected_features = [feature_names[i] for i in range(len(feature_names)) if rfe.support_[i]]\n",
    "print(\"\\nSelected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8068e20c",
   "metadata": {},
   "source": [
    "Step 8: Train the model and print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792e0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e6229",
   "metadata": {},
   "source": [
    "Perform cross validation to get mean F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(model, X_train_balanced, y_train_balanced, cv=5, scoring='f1')\n",
    "print(\"\\n5-Fold CV F1-Scores:\", cv_scores)\n",
    "print(\"Mean CV F1-Score:\", cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e34896b",
   "metadata": {},
   "source": [
    "\n",
    "Feature importance with coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ad50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = pd.DataFrame({'Feature': selected_features, 'Coefficient': model.coef_[0]})\n",
    "print(\"\\nFeature Importance (Coefficients):\\n\", coefficients.sort_values(by='Coefficient', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa3b40",
   "metadata": {},
   "source": [
    "View ROC Curve and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feae5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc_score(y_test, y_pred_proba):.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcbf7f1",
   "metadata": {},
   "source": [
    "Save LR model with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ab946",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, 'logistic_regression_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
